{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import requests\r\n",
    "import re\r\n",
    "import urllib\r\n",
    "import pandas as pd\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from time import sleep\r\n",
    "from random import randint\r\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def get_url(title, location, page):\r\n",
    "    template_url = 'https://www.indeed.com/jobs?q={}&l={}&fromage=14&start={}'\r\n",
    "    url = template_url.format(urllib.parse.quote(title), urllib.parse.quote(location), page)\r\n",
    "    return url"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def get_records(card):\r\n",
    "\r\n",
    "    try:\r\n",
    "        job_title = card.find('h2', {'class':'jobTitle'}).findAll('span')[-1].text\r\n",
    "    except:\r\n",
    "        job_title = ''\r\n",
    "    \r\n",
    "    try:\r\n",
    "        job_conpany = card.find('span', {'class':'companyName'}).text\r\n",
    "    except:\r\n",
    "        job_conpany = ''\r\n",
    "\r\n",
    "    try:\r\n",
    "        job_rating = card.find('span', {'class':'ratingsDisplay withRatingLink'}).text\r\n",
    "    except:\r\n",
    "        job_rating = ''\r\n",
    "    \r\n",
    "    try:\r\n",
    "        job_location = [i.text for i in card.find_all('div', {'class':'companyLocation'})]\r\n",
    "    except:\r\n",
    "        job_location = ''\r\n",
    "    \r\n",
    "    try:\r\n",
    "        job_salary =  card.find('span', {'class':'salary-snippet'}).text\r\n",
    "    except:\r\n",
    "        job_salary = ''\r\n",
    "    \r\n",
    "    try:\r\n",
    "        job_date = card.find('span', {'class':'date'}).text\r\n",
    "    except:\r\n",
    "        job_date = ''\r\n",
    "\r\n",
    "    extract_date = datetime.today().strftime('%Y-%m-%d')\r\n",
    "\r\n",
    "    job_url = 'https://www.indeed.com'+ card['href']\r\n",
    "    return job_title, job_conpany, job_rating, job_location, job_salary, job_date, extract_date, job_url\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "def get_detail(url):\r\n",
    "    res = requests.get(url)\r\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\r\n",
    "\r\n",
    "    #job detail\r\n",
    "    info = {}\r\n",
    "    try:\r\n",
    "        job_detail = soup.find_all('div', {'class':'jobsearch-JobDescriptionSection-sectionItem'})\r\n",
    "        for detail in job_detail:\r\n",
    "            if detail.find('span'):\r\n",
    "                info[detail.find_all('div')[0].text] = [i.text for i in detail.find_all('span')]\r\n",
    "            else:\r\n",
    "                info[detail.find_all('div')[0].text] = [i.text for i in detail.find_all('div')[1:]]\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "    \r\n",
    "    #job qualification\r\n",
    "    try:\r\n",
    "        jobQual = soup.find('div', {'id':'qualificationsSection'})\r\n",
    "        title = jobQual.find('h2').text\r\n",
    "        info[title] = [i.text for i in jobQual.find_all('li', {'class':'icl-u-xs-p--none jobsearch-ReqAndQualSection-item'})]\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "\r\n",
    "    #job description\r\n",
    "    try:\r\n",
    "        jobdesc = soup.find('div', {'id':'jobDescriptionText'})\r\n",
    "        info['Description'] = jobdesc.format_string\r\n",
    "    except:\r\n",
    "        pass\r\n",
    "        \r\n",
    "    res.close()\r\n",
    "    return info\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def get_info(title, location):\r\n",
    "    header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\"}\r\n",
    "    records = []\r\n",
    "    details = []\r\n",
    "    no_of_page = 0\r\n",
    "    for i in range(0, 600, 10):\r\n",
    "        url = get_url(title, location, i)\r\n",
    "        print(url)\r\n",
    "        res = requests.get(url, header)\r\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\r\n",
    "\r\n",
    "        #get total jobs\r\n",
    "        if no_of_page == 0:\r\n",
    "            try:\r\n",
    "                no_of_page_string = soup.find(id='searchCountPages').text.strip()\r\n",
    "                no_of_page = int(re.sub('\\W+', '', no_of_page_string.split()[3]))\r\n",
    "            except:\r\n",
    "                print('No total number')\r\n",
    "                pass\r\n",
    "\r\n",
    "        try:\r\n",
    "            cards = soup.find(id='mosaic-provider-jobcards').findChildren(\"a\" , recursive=False)\r\n",
    "        except:\r\n",
    "            print('No job list')\r\n",
    "            break\r\n",
    "\r\n",
    "        for card in cards:\r\n",
    "            record = get_records(card)\r\n",
    "            records.append(record)\r\n",
    "            wait = randint(5, 12)\r\n",
    "            sleep(wait)\r\n",
    "            detail = get_detail(record[-1])\r\n",
    "            details.append(detail)\r\n",
    "\r\n",
    "        wait = randint(30, 60)\r\n",
    "        sleep(wait)\r\n",
    "\r\n",
    "        # res.close()\r\n",
    "    return records, details, no_of_page*15"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def saveDate(title, records, details):\r\n",
    "    col = ['Title', 'Company', 'Rating', 'Location', 'Salary', 'Post_date', 'Extract_date', 'Job_url']\r\n",
    "    df_basic = pd.DataFrame(records)\r\n",
    "    df_basic.columns = col\r\n",
    "    df_detail = pd.DataFrame.from_dict(details)\r\n",
    "    df = pd.concat([df_basic, df_detail], axis=1)\r\n",
    "    df.to_csv(f'{title}.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "no_of_jobs = {}\r\n",
    "\r\n",
    "#get records from 'Data scientist' in 'UniedStates'\r\n",
    "records, details, total = get_info('Data scientist', 'United states')\r\n",
    "try:\r\n",
    "    saveDate(f'Data scientist', records, details)\r\n",
    "except:\r\n",
    "    print(\"No data stored\")\r\n",
    "no_of_jobs['Data scientist'] = total\r\n",
    "\r\n",
    "# sleep(300)\r\n",
    "# #get records from 'Software programmer' in 'UniedStates'\r\n",
    "# records, details, total = get_info('Software programmer', 'United states')\r\n",
    "# saveDate('Software programmer', records, details)\r\n",
    "# no_of_jobs['Software programmer'] = total\r\n",
    "\r\n",
    "# sleep(300)\r\n",
    "# #get records from 'Web programmer' in 'UniedStates'\r\n",
    "# records, details, total = get_info('Web programme', 'United states')\r\n",
    "# saveDate('Web programmer', records, details)\r\n",
    "# no_of_jobs['Web programmer'] = total\r\n",
    "\r\n",
    "# sleep(300)\r\n",
    "# #get records from 'Information architect' in 'UniedStates'\r\n",
    "# records, details, total = get_info('Information architect', 'United states')\r\n",
    "# saveDate('Information architect', records, details)\r\n",
    "# no_of_jobs['Information architect'] = total"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://www.indeed.com/jobs?q=Data%20scientist&l=United%20states&fromage=14&start=0\n",
      "No total number\n",
      "No job list\n",
      "No data stored\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "no_of_jobs = {}\r\n",
    "\r\n",
    "#get records from 'Data scientist' in 'UniedStates'\r\n",
    "records, details, total = get_info('Data scientist', 'United states')\r\n",
    "saveDate(f'Data scientist', records, details)\r\n",
    "no_of_jobs['Data scientist'] = total\r\n",
    "\r\n",
    "# sleep(300)\r\n",
    "# #get records from 'Software programmer' in 'UniedStates'\r\n",
    "# records, details, total = get_info('Software programmer', 'United states')\r\n",
    "# saveDate('Software programmer', records, details)\r\n",
    "# no_of_jobs['Software programmer'] = total\r\n",
    "\r\n",
    "# sleep(300)\r\n",
    "# #get records from 'Web programmer' in 'UniedStates'\r\n",
    "# records, details, total = get_info('Web programme', 'United states')\r\n",
    "# saveDate('Web programmer', records, details)\r\n",
    "# no_of_jobs['Web programmer'] = total\r\n",
    "\r\n",
    "# sleep(300)\r\n",
    "# #get records from 'Information architect' in 'UniedStates'\r\n",
    "# records, details, total = get_info('Information architect', 'United states')\r\n",
    "# saveDate('Information architect', records, details)\r\n",
    "# no_of_jobs['Information architect'] = total"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://www.indeed.com/jobs?q=Data%20scientist&l=United%20states&fromage=14&start=0\n",
      "No total number\n",
      "No job list\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 8 elements",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14764/1367192978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#get records from 'Data scientist' in 'UniedStates'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data scientist'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'United states'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msaveDate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Data scientist'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mno_of_jobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Data scientist'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14764/3152882020.py\u001b[0m in \u001b[0;36msaveDate\u001b[1;34m(title, records, details)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Company'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Rating'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Location'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Salary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Post_date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Extract_date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Job_url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdf_basic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf_basic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdf_detail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetails\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_basic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_detail\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5489\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5490\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5491\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5492\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5493\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 8 elements"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "no_of_jobs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Data scientist': 108240}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(records)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "c5562ae4cb73c005d4d512b63371f9759c2bba9f1255843d95070cdaa5df3d5e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}